# Lite.AI.ToolKit.Hub.MNN

You can download all the pretrained models files of MNN format from ([Baidu Drive](https://pan.baidu.com/s/1KyO-bCYUv6qPq2M8BH_Okg) code: 9v63) 

## Object Detection.

<div id="lite.ai.toolkit.hub.mnn-object-detection"></div>

|                 Class                 |      Pretrained MNN Files      |              Rename or Converted From (Repo)              | Size  |
| :-----------------------------------: | :-----------------------------: | :-------------------------------------------------------: | :---: |
| *lite::mnn::cv::detection::NanoDet* |    nanodet_m_0.5x.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 1.1Mb  |
| *lite::mnn::cv::detection::NanoDet* |    nanodet_m.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 3.6Mb  |
| *lite::mnn::cv::detection::NanoDet* |    nanodet_m_1.5x.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 7.9Mb  |
| *lite::mnn::cv::detection::NanoDet* |    nanodet_m_1.5x_416.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 7.9Mb  |
| *lite::mnn::cv::detection::NanoDet* |    nanodet_m_416.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 3.6Mb  |
| *lite::mnn::cv::detection::NanoDet* |    nanodet_g.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 14Mb  |
| *lite::mnn::cv::detection::NanoDet* |    nanodet_t.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 5.1Mb  |
| *lite::mnn::cv::detection::NanoDet* |    nanodet-RepVGG-A0_416.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 26Mb  |
| *lite::mnn::cv::detection::NanoDetEfficientNetLite* |    nanodet-EfficientNet-Lite0_320.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 12Mb  |
| *lite::mnn::cv::detection::NanoDetEfficientNetLite* |    nanodet-EfficientNet-Lite1_416.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 15Mb  |
| *lite::mnn::cv::detection::NanoDetEfficientNetLite* |    nanodet-EfficientNet-Lite2_512.mnn     |       [nanodet](https://github.com/RangiLyu/nanodet)       | 18Mb  |
|     *lite::mnn::cv::detection::YoloX*      |          yolox_x.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 378Mb |
|     *lite::mnn::cv::detection::YoloX*      |          yolox_l.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 207Mb |
|     *lite::mnn::cv::detection::YoloX*      |          yolox_m.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 97Mb  |
|     *lite::mnn::cv::detection::YoloX*      |          yolox_s.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 34Mb  |
|     *lite::mnn::cv::detection::YoloX*      |         yolox_tiny.mnn         |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 19Mb  |
|     *lite::mnn::cv::detection::YoloX*      |         yolox_nano.mnn         |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 3.5Mb |
|     *lite::mnn::cv::detection::YOLOP*      |       yolop-320-320.mnn           |  [YOLOP](https://github.com/hustvl/YOLOP)   | 30Mb  |
|     *lite::mnn::cv::detection::YOLOP*      |       yolop-640-640.mnn         |  [YOLOP](https://github.com/hustvl/YOLOP)   | 30Mb  |
|     *lite::mnn::cv::detection::YOLOP*      |       yolop-1280-1280.mnn         |  [YOLOP](https://github.com/hustvl/YOLOP)   | 30Mb |
|     *lite::mnn::cv::detection::YoloV5*     |          yolov5l.mnn            |      [yolov5](https://github.com/ultralytics/yolov5)      | 188Mb |
|     *lite::mnn::cv::detection::YoloV5*     |          yolov5m.mnn            |      [yolov5](https://github.com/ultralytics/yolov5)      | 85Mb  |
|     *lite::mnn::cv::detection::YoloV5*     |          yolov5s.mnn            |      [yolov5](https://github.com/ultralytics/yolov5)      | 29Mb  |
|     *lite::mnn::cv::detection::YoloV5*     |          yolov5x.mnn            |      [yolov5](https://github.com/ultralytics/yolov5)      | 351Mb | 
|     *lite::mnn::cv::detection::YoloX_V_0_1_1*      |          yolox_x_v0.1.1.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 378Mb |
|     *lite::mnn::cv::detection::YoloX_V_0_1_1*      |          yolox_l_v0.1.1.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 207Mb |
|     *lite::mnn::cv::detection::YoloX_V_0_1_1*      |          yolox_m_v0.1.1.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 97Mb  |
|     *lite::mnn::cv::detection::YoloX_V_0_1_1*      |          yolox_s_v0.1.1.mnn           |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 34Mb  |
|     *lite::mnn::cv::detection::YoloX_V_0_1_1*      |         yolox_tiny_v0.1.1.mnn         |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 19Mb  |
|     *lite::mnn::cv::detection::YoloX_V_0_1_1*      |         yolox_nano_v0.1.1.mnn         |  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)   | 3.5Mb |
|     *lite::mnn::cv::detection::YoloR*     |          yolor-p6-320-320.mnn            |      [yolor](https://github.com/WongKinYiu/yolor)      | 157Mb |
|     *lite::mnn::cv::detection::YoloR*     |          yolor-p6-640-640.mnn            |      [yolor](https://github.com/WongKinYiu/yolor)      | 157Mb  |
|     *lite::mnn::cv::detection::YoloR*     |          yolor-ssss-s2d-640-640.mnn            |      [yolor](https://github.com/WongKinYiu/yolor)      | 50Mb  |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5l.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 178Mb |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5m.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 81Mb  |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5s.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 28Mb  |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5n.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 7.5Mb |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5l6.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 294Mb |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5m6.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 128Mb  |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5s6.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 50Mb  |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5n6.640-640.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 14Mb |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5l6.1280-1280.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 294Mb |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5m6.1280-1280.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 128Mb  |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5s6.1280-1280.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 50Mb  |
|     *lite::mnn::cv::detection::YoloV5_V_6_0*     |          yolov5n6.1280-1280.v.6.0.mnn           |      [yolov5](https://github.com/ultralytics/yolov5)      | 14Mb |


## Matting.

<div id="lite.ai.toolkit.hub.mnn-matting"></div>

|                Class                | Pretrained MNN Files |              Rename or Converted From (Repo)              | Size  |
| :---------------------------------: | :-------------------: | :-------------------------------------------------------: | :---: |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_mobilenetv3_fp32.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 14Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_mobilenetv3_fp32-480-480.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 14Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_mobilenetv3_fp32-480-640.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 14Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_mobilenetv3_fp32-640-480.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 14Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_mobilenetv3_fp32-1080-1920.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 14Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_resnet50_fp32.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 50Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_resnet50_fp32-480-480.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 50Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_resnet50_fp32-480-640.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 50Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_resnet50_fp32-640-480.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 50Mb |
| *lite::mnn::cv::matting::RobustVideoMatting* |   rvm_resnet50_fp32-1080-1920.mnn   | [RobustVideoMatting](https://github.com/PeterL1n/RobustVideoMatting) | 50Mb |
| *lite::mnn::cv::matting::MGMatting* |   MGMatting-DIM-100k.mnn   | [MGMatting](https://github.com/yucornetto/MGMatting) | 113Mb |
| *lite::mnn::cv::matting::MGMatting* |   MGMatting-RWP-100k.mnn   | [MGMatting](https://github.com/yucornetto/MGMatting) | 113Mb |

## Face Recognition.

<div id="lite.ai.toolkit.hub.mnn-face-recognition"></div>  


|                   Class                   |            Pretrained MNN Files             |               Rename or Converted From (Repo)                | Size  |
| :---------------------------------------: | :------------------------------------------: | :----------------------------------------------------------: | :---: |
|     *lite::mnn::cv::faceid::GlintArcFace*      |           ms1mv3_arcface_r100.mnn           |  [insightface](https://github.com/deepinsight/insightface)   | 248Mb |
|     *lite::mnn::cv::faceid::GlintArcFace*      |           ms1mv3_arcface_r50.mnn            |  [insightface](https://github.com/deepinsight/insightface)   | 166Mb |
|     *lite::mnn::cv::faceid::GlintArcFace*      |           ms1mv3_arcface_r34.mnn            |  [insightface](https://github.com/deepinsight/insightface)   | 130Mb |
|     *lite::mnn::cv::faceid::GlintArcFace*      |           ms1mv3_arcface_r18.mnn            |  [insightface](https://github.com/deepinsight/insightface)   | 91Mb  |
|     *lite::mnn::cv::faceid::GlintCosFace*      |         glint360k_cosface_r100.mnn          |  [insightface](https://github.com/deepinsight/insightface)   | 248Mb |
|     *lite::mnn::cv::faceid::GlintCosFace*      |          glint360k_cosface_r50.mnn          |  [insightface](https://github.com/deepinsight/insightface)   | 166Mb |
|     *lite::mnn::cv::faceid::GlintCosFace*      |          glint360k_cosface_r34.mnn          |  [insightface](https://github.com/deepinsight/insightface)   | 130Mb |
|     *lite::mnn::cv::faceid::GlintCosFace*      |          glint360k_cosface_r18.mnn          |  [insightface](https://github.com/deepinsight/insightface)   | 91Mb  |
|    *lite::mnn::cv::faceid::GlintPartialFC*     |        partial_fc_glint360k_r100.mnn        |  [insightface](https://github.com/deepinsight/insightface)   | 248Mb |
|    *lite::mnn::cv::faceid::GlintPartialFC*     |        partial_fc_glint360k_r50.mnn         |  [insightface](https://github.com/deepinsight/insightface)   | 91Mb  |
|        *lite::mnn::cv::faceid::FaceNet*        |         facenet_vggface2_resnet.mnn         |  [facenet...](https://github.com/timesler/facenet-pytorch)   | 89Mb  |
|        *lite::mnn::cv::faceid::FaceNet*        |      facenet_casia-webface_resnet.mnn       |  [facenet...](https://github.com/timesler/facenet-pytorch)   | 89Mb  |
|     *lite::mnn::cv::faceid::FocalArcFace*      |        focal-arcface-ms1m-ir152.mnn         | [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch) | 269Mb |
|     *lite::mnn::cv::faceid::FocalArcFace*      |    focal-arcface-ms1m-ir50-epoch120.mnn     | [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch) | 166Mb |
|     *lite::mnn::cv::faceid::FocalArcFace*      |     focal-arcface-ms1m-ir50-epoch63.mnn     | [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch) | 166Mb |
|   *lite::mnn::cv::faceid::FocalAsiaArcFace*    |       focal-arcface-bh-ir50-asia.mnn        | [face.evoLVe...](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch) | 166Mb |
| *lite::mnn::cv::faceid::TencentCurricularFace* |     Tencent_CurricularFace_Backbone.mnn     |          [TFace](https://github.com/Tencent/TFace)           | 249Mb |
|    *lite::mnn::cv::faceid::TencentCifpFace*    |  Tencent_Cifp_BUPT_Balancedface_IR_34.mnn   |          [TFace](https://github.com/Tencent/TFace)           | 130Mb |
|    *lite::mnn::cv::faceid::CenterLossFace*     |        CenterLossFace_epoch_100.mnn         | [center-loss...](https://github.com/louis-she/center-loss.pytorch) | 280Mb |
|      *lite::mnn::cv::faceid::SphereFace*       |           sphere20a_20171020.mnn            | [sphere...](https://github.com/clcarwin/sphereface_pytorch)  | 86Mb  |
|     *lite::mnn::cv::faceid:MobileFaceNet*      |        MobileFaceNet_Pytorch_068.mnn        | [MobileFace...](https://github.com/Xiaoccer/MobileFaceNet_Pytorch) | 3.8Mb |
|    *lite::mnn::cv::faceid:CavaGhostArcFace*    | cavaface_GhostNet_x1.3_Arcface_Epoch_24.mnn | [cavaface...](https://github.com/cavalleria/cavaface.pytorch) | 15Mb  |
|    *lite::mnn::cv::faceid:CavaCombinedFace*    |  cavaface_IR_SE_100_Combined_Epoch_24.mnn   | [cavaface...](https://github.com/cavalleria/cavaface.pytorch) | 250Mb |
|    *lite::mnn::cv::faceid:MobileSEFocalFace*   | face_recognition.pytorch_Mobilenet_se_focal_121000.mnn | [face_recog...](https://github.com/grib0ed0v/face_recognition.pytorch) | 4.5Mb |

## Face Detection.

<div id="lite.ai.toolkit.hub.mnn-face-detection"></div>  

|                Class                | Pretrained MNN Files  |               Rename or Converted From (Repo)                | Size  |
| :---------------------------------: | :--------------------: | :----------------------------------------------------------: | :---: |
| *lite::mnn::cv::face::detect::UltraFace* | ultraface-rfb-320.mnn | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.5Mb |
| *lite::mnn::cv::face::detect::UltraFace* | ultraface-rfb-640.mnn | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.5Mb |
| *lite::mnn::cv::face::detect::UltraFace* | ultraface-slim-320.mnn | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.2Mb |
| *lite::mnn::cv::face::detect::UltraFace* | ultraface-slim-640.mnn | [Ultra-Light...](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB) | 1.2Mb |
| *lite::mnn::cv::face::detect::RetinaFace* | Pytorch_RetinaFace_mobile0.25.mnn | [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface) | 1.6Mb |
| *lite::mnn::cv::face::detect::RetinaFace* | Pytorch_RetinaFace_mobile0.25-640-640.mnn | [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface) | 1.6Mb |
| *lite::mnn::cv::face::detect::RetinaFace* | Pytorch_RetinaFace_mobile0.25-320-320.mnn | [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface) | 1.6Mb |
| *lite::mnn::cv::face::detect::RetinaFace* | Pytorch_RetinaFace_mobile0.25-720-1080.mnn | [...Retinaface](https://github.com/biubug6/Pytorch_Retinaface) | 1.6Mb |
| *lite::mnn::cv::face::detect::FaceBoxes* | FaceBoxes.mnn | [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)  | 3.8Mb |
| *lite::mnn::cv::face::detect::FaceBoxes* | FaceBoxes-640-640.mnn | [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)  | 3.8Mb |
| *lite::mnn::cv::face::detect::FaceBoxes* | FaceBoxes-320-320.mnn | [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)  | 3.8Mb |
| *lite::mnn::cv::face::detect::FaceBoxes* | FaceBoxes-720-1080.mnn | [FaceBoxes](https://github.com/zisianw/FaceBoxes.PyTorch)  | 3.8Mb |

## Face Alignment.

<div id="lite.ai.toolkit.hub.mnn-face-alignment"></div>  


|             Class             | Pretrained MNN Files |               Rename or Converted From (Repo)                | Size  |
| :---------------------------: | :-------------------: | :----------------------------------------------------------: | :---: |
| *lite::mnn::cv::face::align::PFLD* |  pfld-106-lite.mnn   | [pfld_106_...](https://github.com/Hsintao/pfld_106_face_landmarks) | 1.0Mb |
| *lite::mnn::cv::face::align::PFLD* |   pfld-106-v3.mnn    | [pfld_106_...](https://github.com/Hsintao/pfld_106_face_landmarks) | 5.5Mb |
| *lite::mnn::cv::face::align::PFLD* |   pfld-106-v2.mnn    | [pfld_106_...](https://github.com/Hsintao/pfld_106_face_landmarks) | 5.0Mb |
| *lite::mnn::cv::face::align::PFLD98* |   PFLD-pytorch-pfld.mnn  | [PFLD...](https://github.com/polarisZhao/PFLD-pytorch) | 4.8Mb |
| *lite::mnn::cv::face::align::MobileNetV268* |   pytorch_face_landmarks_landmark_detection_56.mnn  | [...landmark](https://github.com/cunjian/pytorch_face_landmark) | 9.4Mb |
| *lite::mnn::cv::face::align::MobileNetV2SE68* |   pytorch_face_landmarks_landmark_detection_56_se_external.mnn  | [...landmark](https://github.com/cunjian/pytorch_face_landmark) | 11Mb |
| *lite::mnn::cv::face::align::PFLD68* |   pytorch_face_landmarks_pfld.mnn | [...landmark](https://github.com/cunjian/pytorch_face_landmark) | 2.8Mb |
| *lite::mnn::cv::face::align::FaceLandmarks1000* |   FaceLandmark1000.mnn  | [FaceLandm...](https://github.com/Single430/FaceLandmark1000) | 2.0Mb |

## Head Pose Estimation.

<div id="lite.ai.toolkit.hub.mnn-head-pose-estimation"></div>  


|             Class              | Pretrained MNN Files |               Rename or Converted From (Repo)                | Size  |
| :----------------------------: | :-------------------: | :----------------------------------------------------------: | :---: |
| *lite::mnn::cv::face::pose::FSANet* |    fsanet-var.mnn    | [...fsanet...](https://github.com/omasaht/headpose-fsanet-pytorch) | 1.2Mb |
| *lite::mnn::cv::face::pose::FSANet* |    fsanet-1x1.mnn   | [...fsanet...](https://github.com/omasaht/headpose-fsanet-pytorch) | 1.2Mb |

## Face Attributes.

<div id="lite.ai.toolkit.hub.mnn-face-attributes"></div>  


|                  Class                  |          Pretrained MNN Files           |             Rename or Converted From (Repo)              | Size  |
| :-------------------------------------: | :--------------------------------------: | :------------------------------------------------------: | :---: |
|  *lite::mnn::cv::face::attr::AgeGoogleNet*   |            age_googlenet.mnn            |      [onnx-models](https://github.com/onnx/models)       | 23Mb  |
| *lite::mnn::cv::face::attr::GenderGoogleNet* |          gender_googlenet.mnn           |      [onnx-models](https://github.com/onnx/models)       | 23Mb  |
| *lite::mnn::cv::face::attr::EmotionFerPlus*  |          emotion-ferplus-7.mnn          |      [onnx-models](https://github.com/onnx/models)       | 33Mb  |
| *lite::mnn::cv::face::attr::EmotionFerPlus*  |          emotion-ferplus-8.mnn          |      [onnx-models](https://github.com/onnx/models)       | 33Mb  |
|     *lite::mnn::cv::face::attr::SSRNet*      |               ssrnet.mnn                | [SSR_Net...](https://github.com/oukohou/SSR_Net_Pytorch) | 190Kb |
|     *lite::mnn::cv::face::attr::EfficientEmotion7*      |  face-emotion-recognition-enet_b0_7.mnn  | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 15Mb |
|     *lite::mnn::cv::face::attr::EfficientEmotion8*      |  face-emotion-recognition-enet_b0_8_best_afew.mnn | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 15Mb |
|     *lite::mnn::cv::face::attr::EfficientEmotion8*      |  face-emotion-recognition-enet_b0_8_best_vgaf.mnn | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 15Mb |
|     *lite::mnn::cv::face::attr::MobileEmotion7*      |   face-emotion-recognition-mobilenet_7.mnn  | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition)| 13Mb |
|     *lite::mnn::cv::face::attr::ReXNetEmotion7*      | face-emotion-recognition-affectnet_7_vggface2_rexnet150.mnn | [face-emo...](https://github.com/HSE-asavchenko/face-emotion-recognition) | 30Mb |

## Classification.

<div id="lite.ai.toolkit.hub.mnn-classification"></div>


|                    Class                     |   Pretrained MNN Files    |         Rename or Converted From (Repo)          | Size  |
| :------------------------------------------: | :------------------------: | :----------------------------------------------: | :---: |
| *lite::mnn::cv::classification:EfficientNetLite4* | efficientnet-lite4-11.mnn |  [onnx-models](https://github.com/onnx/models)   | 49Mb  |
|   *lite::mnn::cv::classification::ShuffleNetV2*   |   shufflenet-v2-10.mnn    |  [onnx-models](https://github.com/onnx/models)   | 8.7Mb |
|   *lite::mnn::cv::classification::DenseNet121*    |      densenet121.mnn      | [torchvision](https://github.com/pytorch/vision) | 30Mb  |
|     *lite::mnn::cv::classification::GhostNet*     |       ghostnet.mnn        | [torchvision](https://github.com/pytorch/vision) | 20Mb  |
|     *lite::mnn::cv::classification::HdrDNet*      |        hardnet.mnn        | [torchvision](https://github.com/pytorch/vision) | 13Mb  |
|      *lite::mnn::cv::classification::IBNNet*      |       ibnnet18.mnn        | [torchvision](https://github.com/pytorch/vision) | 97Mb  |
|   *lite::mnn::cv::classification::MobileNetV2*    |      mobilenetv2.mnn      | [torchvision](https://github.com/pytorch/vision) | 13Mb  |
|      *lite::mnn::cv::classification::ResNet*      |       resnet18.mnn        | [torchvision](https://github.com/pytorch/vision) | 44Mb  |
|     *lite::mnn::cv::classification::ResNeXt*      |        resnext.mnn        | [torchvision](https://github.com/pytorch/vision) | 95Mb  |


## Segmentation.

<div id="lite.ai.toolkit.hub.mnn-segmentation"></div>  


|                    Class                     |     Pretrained MNN Files     |         Rename or Converted From (Repo)          | Size  |
| :------------------------------------------: | :---------------------------: | :----------------------------------------------: | :---: |
| *lite::mnn::cv::segmentation::DeepLabV3ResNet101* | deeplabv3_resnet101_coco.mnn | [torchvision](https://github.com/pytorch/vision) | 232Mb |
|    *lite::mnn::cv::segmentation::FCNResNet101*    |      fcn_resnet101.mnn       | [torchvision](https://github.com/pytorch/vision) | 207Mb |


## Style Transfer.

<div id="lite.ai.toolkit.hub.mnn-style-transfer"></div>  

|                Class                 |   Pretrained MNN Files    |        Rename or Converted From (Repo)        | Size  |
| :----------------------------------: | :------------------------: | :-------------------------------------------: | :---: |
| *lite::mnn::cv::style::FastStyleTransfer* |    style-mosaic-8.mnn     | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* |     style-candy-9.mnn     | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* |     style-udnie-8.mnn     | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* |     style-udnie-9.mnn     | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* |  style-pointilism-8.mnn   | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* |  style-pointilism-9.mnn   | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* | style-rain-princess-9.mnn | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* | style-rain-princess-8.mnn | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* |     style-candy-8.mnn     | [onnx-models](https://github.com/onnx/models) | 6.4Mb |
| *lite::mnn::cv::style::FastStyleTransfer* |    style-mosaic-9.mnn     | [onnx-models](https://github.com/onnx/models) | 6.4Mb |


## Colorization.

<div id="lite.ai.toolkit.hub.mnn-colorization"></div>

|                Class                |   Pretrained MNN Files   |              Rename or Converted From (Repo)              | Size  |
| :---------------------------------: | :-----------------------: | :-------------------------------------------------------: | :---: |
| *lite::mnn::cv::colorization::Colorizer* |   eccv16-colorizer.mnn   | [colorization](https://github.com/richzhang/colorization) | 123Mb |
| *lite::mnn::cv::colorization::Colorizer* | siggraph17-colorizer.mnn | [colorization](https://github.com/richzhang/colorization) | 129Mb |


## Super Resolution.

<div id="lite.ai.toolkit.hub.mnn-super-resolution"></div>

|                Class                | Pretrained MNN Files |              Rename or Converted From (Repo)              | Size  |
| :---------------------------------: | :-------------------: | :-------------------------------------------------------: | :---: |
| *lite::mnn::cv::resolution::SubPixelCNN* |   subpixel-cnn.mnn   | [...PIXEL...](https://github.com/niazwazir/SUB_PIXEL_CNN) | 234Kb |

